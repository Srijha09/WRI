{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re, numpy as np, pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim, spacy, logging, warnings\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import lemmatize, simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use', 'not', 'would', 'say', 'could', '_', 'be', 'know', 'good', 'go', 'get', 'do', 'done', 'try', 'many', 'some', 'nice', 'thank', 'think', 'see', 'rather', 'easy', 'easily', 'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', 'even', 'right', 'line', 'even', 'also', 'may', 'take', 'come'])\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2361, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>From: irwin@cmptrc.lonestar.org (Irwin Arnstei...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>From: leunggm@odin.control.utoronto.ca (Gary L...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>From: jonh@david.wheaton.edu (Jonathan Hayward...</td>\n",
       "      <td>15</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>From: ayr1@cunixa.cc.columbia.edu (Amir Y Rose...</td>\n",
       "      <td>17</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>From: dchhabra@stpl.ists.ca (Deepak Chhabra)\\n...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content  target  \\\n",
       "10  From: irwin@cmptrc.lonestar.org (Irwin Arnstei...       8   \n",
       "21  From: leunggm@odin.control.utoronto.ca (Gary L...      10   \n",
       "28  From: jonh@david.wheaton.edu (Jonathan Hayward...      15   \n",
       "33  From: ayr1@cunixa.cc.columbia.edu (Amir Y Rose...      17   \n",
       "35  From: dchhabra@stpl.ists.ca (Deepak Chhabra)\\n...      10   \n",
       "\n",
       "              target_names  \n",
       "10         rec.motorcycles  \n",
       "21        rec.sport.hockey  \n",
       "28  soc.religion.christian  \n",
       "33   talk.politics.mideast  \n",
       "35        rec.sport.hockey  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Dataset\n",
    "df = pd.read_json('https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json')\n",
    "df = df.loc[df.target_names.isin(['soc.religion.christian', 'rec.sport.hockey', 'talk.politics.mideast', 'rec.motorcycles']) , :]\n",
    "print(df.shape)  #> (2361, 3)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['from', 'irwin', 'arnstein', 'subject', 're', 'recommendation', 'on', 'duc', 'summary', 'whats', 'it', 'worth', 'distribution', 'usa', 'expires', 'sat', 'may', 'gmt', 'organization', 'computrac', 'inc', 'richardson', 'tx', 'keywords', 'ducati', 'gts', 'how', 'much', 'lines', 'have', 'line', 'on', 'ducati', 'gts', 'model', 'with', 'on', 'the', 'clock', 'runs', 'very', 'well', 'paint', 'is', 'the', 'bronze', 'brown', 'orange', 'faded', 'out', 'leaks', 'bit', 'of', 'oil', 'and', 'pops', 'out', 'of', 'st', 'with', 'hard', 'accel', 'the', 'shop', 'will', 'fix', 'trans', 'and', 'oil', 'leak', 'they', 'sold', 'the', 'bike', 'to', 'the', 'and', 'only', 'owner', 'they', 'want', 'and', 'am', 'thinking', 'more', 'like', 'any', 'opinions', 'out', 'there', 'please', 'email', 'me', 'thanks', 'it', 'would', 'be', 'nice', 'stable', 'mate', 'to', 'the', 'beemer', 'then', 'ill', 'get', 'jap', 'bike', 'and', 'call', 'myself', 'axis', 'motors', 'tuba', 'irwin', 'honk', 'therefore', 'am', 'computrac', 'richardson', 'tx', 'dod']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sent in sentences:\n",
    "        sent = re.sub('\\S*@\\S*\\s?', '', sent)  # remove emails\n",
    "        sent = re.sub('\\s+', ' ', sent)  # remove newline chars\n",
    "        sent = re.sub(\"\\'\", \"\", sent)  # remove single quotes\n",
    "        sent = gensim.utils.simple_preprocess(str(sent), deacc=True) \n",
    "        yield(sent)  \n",
    "\n",
    "# Convert to list\n",
    "data = df.content.values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "print(data_words[:1])\n",
    "# [['from', 'irwin', 'arnstein', 'subject', 're', 'recommendation', 'on', 'duc', 'summary', 'whats', 'it', 'worth', 'distribution', 'usa', 'expires', 'sat', 'may', 'gmt', ...trucated...]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# !python3 -m spacy download en  # run in terminal once\n",
    "def process_words(texts, stop_words=stop_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"Remove Stopwords, Form Bigrams, Trigrams and Lemmatization\"\"\"\n",
    "    texts = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "    texts = [bigram_mod[doc] for doc in texts]\n",
    "    texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "    texts_out = []\n",
    "    nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    # remove stopwords once more after lemmatization\n",
    "    texts_out = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts_out]    \n",
    "    return texts_out\n",
    "\n",
    "data_ready = process_words(data_words)  # processed Text Data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.017*\"israel\" + 0.011*\"israeli\" + 0.010*\"greek\" + 0.010*\"armenian\" + '\n",
      "  '0.008*\"arab\" + 0.008*\"kill\" + 0.007*\"turk\" + 0.007*\"war\" + 0.007*\"state\" + '\n",
      "  '0.007*\"government\"'),\n",
      " (1,\n",
      "  '0.012*\"god\" + 0.010*\"people\" + 0.010*\"write\" + 0.008*\"organization\" + '\n",
      "  '0.006*\"believe\" + 0.006*\"time\" + 0.006*\"reason\" + 0.006*\"christian\" + '\n",
      "  '0.005*\"way\" + 0.005*\"thing\"'),\n",
      " (2,\n",
      "  '0.024*\"team\" + 0.018*\"game\" + 0.014*\"hockey\" + 0.010*\"play\" + 0.010*\"year\" '\n",
      "  '+ 0.009*\"win\" + 0.009*\"player\" + 0.008*\"nhl\" + 0.007*\"organization\" + '\n",
      "  '0.007*\"playoff\"'),\n",
      " (3,\n",
      "  '0.014*\"organization\" + 0.012*\"bike\" + 0.011*\"write\" + 0.009*\"article\" + '\n",
      "  '0.007*\"california\" + 0.006*\"rider\" + 0.006*\"cbr_rr\" + 0.006*\"steal\" + '\n",
      "  '0.005*\"motorcycle\" + 0.005*\"pasadena\"')]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_ready)\n",
    "\n",
    "# Create Corpus: Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in data_ready]\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=4, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=10,\n",
    "                                           passes=10,\n",
    "                                           alpha='symmetric',\n",
    "                                           iterations=100,\n",
    "                                           per_word_topics=True)\n",
    "\n",
    "pprint(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2361"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the Dominant topic and its percentage contribution in each document\n",
    "\n",
    "def format_topics_sentences(ldamodel=None, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "        # print(row)\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data_ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8628</td>\n",
       "      <td>organization, bike, write, article, california...</td>\n",
       "      <td>[irwin, arnstein, recommendation, duc, summary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7437</td>\n",
       "      <td>team, game, hockey, play, year, win, player, n...</td>\n",
       "      <td>[gary, leung, organization, university, toront...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8892</td>\n",
       "      <td>god, people, write, organization, believe, tim...</td>\n",
       "      <td>[hayward, pantheism, organization, wheaton, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6653</td>\n",
       "      <td>israel, israeli, greek, armenian, arab, kill, ...</td>\n",
       "      <td>[amir_rosenblatt, reply, amir_rosenblatt, orga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4872</td>\n",
       "      <td>team, game, hockey, play, year, win, player, n...</td>\n",
       "      <td>[deepak_chhabra, goalie_mask, ists_ca, organiz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4981</td>\n",
       "      <td>organization, bike, write, article, california...</td>\n",
       "      <td>[joe, ehrlich, bmw_moa_member, read, organizat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.7198</td>\n",
       "      <td>organization, bike, write, article, california...</td>\n",
       "      <td>[chris_behanna, require, organization, article...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6277</td>\n",
       "      <td>organization, bike, write, article, california...</td>\n",
       "      <td>[speedy_mercer, look, movie, bike, organizatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9659</td>\n",
       "      <td>god, people, write, organization, believe, tim...</td>\n",
       "      <td>[darius_lecointe, organization, florida_state,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6486</td>\n",
       "      <td>israel, israeli, greek, armenian, arab, kill, ...</td>\n",
       "      <td>[serdar_argic, day, night, armenian, round, ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0             3.0              0.8628   \n",
       "1            1             2.0              0.7437   \n",
       "2            2             1.0              0.8892   \n",
       "3            3             0.0              0.6653   \n",
       "4            4             2.0              0.4872   \n",
       "5            5             3.0              0.4981   \n",
       "6            6             3.0              0.7198   \n",
       "7            7             3.0              0.6277   \n",
       "8            8             1.0              0.9659   \n",
       "9            9             0.0              0.6486   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  organization, bike, write, article, california...   \n",
       "1  team, game, hockey, play, year, win, player, n...   \n",
       "2  god, people, write, organization, believe, tim...   \n",
       "3  israel, israeli, greek, armenian, arab, kill, ...   \n",
       "4  team, game, hockey, play, year, win, player, n...   \n",
       "5  organization, bike, write, article, california...   \n",
       "6  organization, bike, write, article, california...   \n",
       "7  organization, bike, write, article, california...   \n",
       "8  god, people, write, organization, believe, tim...   \n",
       "9  israel, israeli, greek, armenian, arab, kill, ...   \n",
       "\n",
       "                                                Text  \n",
       "0  [irwin, arnstein, recommendation, duc, summary...  \n",
       "1  [gary, leung, organization, university, toront...  \n",
       "2  [hayward, pantheism, organization, wheaton, co...  \n",
       "3  [amir_rosenblatt, reply, amir_rosenblatt, orga...  \n",
       "4  [deepak_chhabra, goalie_mask, ists_ca, organiz...  \n",
       "5  [joe, ehrlich, bmw_moa_member, read, organizat...  \n",
       "6  [chris_behanna, require, organization, article...  \n",
       "7  [speedy_mercer, look, movie, bike, organizatio...  \n",
       "8  [darius_lecointe, organization, florida_state,...  \n",
       "9  [serdar_argic, day, night, armenian, round, ma...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Representative Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9963</td>\n",
       "      <td>israel, israeli, greek, armenian, arab, kill, turk, war, state, government</td>\n",
       "      <td>[serdar_argic, armenian, genocide, muslim, people, article, zuma, reply, article, panos_tamamidi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>god, people, write, organization, believe, time, reason, christian, way, thing</td>\n",
       "      <td>[arrogance, christian, usa, article, carol_alvin, write, write, hold, scripture, true, however, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9977</td>\n",
       "      <td>team, game, hockey, play, year, win, player, nhl, organization, playoff</td>\n",
       "      <td>[bryan, strouse, nhl, result, game, play, organization, keyword, thursday, night, boxscore, nhl,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.9747</td>\n",
       "      <td>organization, bike, write, article, california, rider, cbr_rr, steal, motorcycle, pasadena</td>\n",
       "      <td>[beavington, insurance, lotsa_point, reply, organization, dms, software, design, article, andrew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Num  Topic_Perc_Contrib  \\\n",
       "0        0.0              0.9963   \n",
       "1        1.0              0.9972   \n",
       "2        2.0              0.9977   \n",
       "3        3.0              0.9747   \n",
       "\n",
       "                                                                                     Keywords  \\\n",
       "0                  israel, israeli, greek, armenian, arab, kill, turk, war, state, government   \n",
       "1              god, people, write, organization, believe, time, reason, christian, way, thing   \n",
       "2                     team, game, hockey, play, year, win, player, nhl, organization, playoff   \n",
       "3  organization, bike, write, article, california, rider, cbr_rr, steal, motorcycle, pasadena   \n",
       "\n",
       "                                                                                   Representative Text  \n",
       "0  [serdar_argic, armenian, genocide, muslim, people, article, zuma, reply, article, panos_tamamidi...  \n",
       "1  [arrogance, christian, usa, article, carol_alvin, write, write, hold, scripture, true, however, ...  \n",
       "2  [bryan, strouse, nhl, result, game, play, organization, keyword, thursday, night, boxscore, nhl,...  \n",
       "3  [beavington, insurance, lotsa_point, reply, organization, dms, software, design, article, andrew...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display setting to show more characters in column\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=False).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Representative Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
